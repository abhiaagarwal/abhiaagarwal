---
title: ChatGPT 4o (04/26/25) is the most dangerous AI ever released.
description: 'OpenAI published a seemingly "minor" update to ChatGPT 4o. It engages in dangerous levels of sycophancy that could have drastic second-order effects.'
tags: [thoughts]
---

I'm an AI optimist. I would say that the probability of AI leading to an utopic future is higher than one that would lead to our downfall, the so-called [P(doom)](https://en.wikipedia.org/wiki/P(doom)).

OpenAI is causing me to question that.

OpenAI has been continually post-training its standard model, ChatGPT 4o, both with reasoning traces from their higher tiered o3/4 models, as well as tuning for human preferences (RLHF). ChatGPT has a billion users, and even if 1% of those are clicking those thumbs up/down buttons, OpenAI possesses the world's strongest human preferences dataset. Unfortunately, the average person does not possess good taste. Those human preferences have caused their model to display highly sycophantic behavior.

To demonstrate, here's a conversation where I convinced ChatGPT that I was the messiah in about 5 chats. Here's another chat, _with memory turned off_, where it told me I possess an IQ of 150-180. There's another one, where I unambiguously gave it a scenario modeled off of an *Am I the Asshole* post where I am unambiguously the asshole, and it told me I was most certainly not the asshole.

If you look at the trends for AI usage, an increasing proportion of people are using it as a substitute for a therapist. On some level I get it â€” even I've vented (to [[Content/ai/llms/reviews/claude/claude-sonnet-3.5|claude-sonnet-3.5]]) a few times. Interacting with other humans in an authentic sense.

Even though I make fun of them, I'm beginning to understand Anthropic's dedication towards AI safety and model alignment.